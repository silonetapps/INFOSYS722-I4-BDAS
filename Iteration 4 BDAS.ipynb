{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 01-BU\n",
    "INFOSYS722 - Iteration 4 - BDAS\n",
    "Author: S. Schmidt<br>Date: 10/05/2024<br>\n",
    "Desc: Primary question: Is the date the UN set of the year 2030 achievable for Goal 2, Zero world hunger?<br><br>\n",
    "This Spark program reads in the Global Health Index values collected for each country and calculates a Mean value<br>\n",
    "for each collected year. <br>This mean value is then used to predict the date when \"Zero Hunger\" will be reached and in turn, provide insight into when Zero Hunger will be reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 02-DU\n",
    "Load up libraries and retrieve datasource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "\n",
    "#from pyspark.sql.SQLContext import sqlContext\n",
    "spark = SparkSession.builder.appName('predict_un_ghi_target_date').getOrCreate()\n",
    "#from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "#from pyspark.pandas import pypandas\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#platform = sys.platform\n",
    "#recur_limit = sys.getrecursionlimit()\n",
    "#print(\"The recursion limit for %s platform is %s\" % (platform, recur_limit))\n",
    "#sys.setrecursionlimit(1000)\n",
    "#new_recur_limit = sys.getrecursionlimit()\n",
    "#print(\"The new recursion limit for %s platform is %s\" % (platform, new_recur_limit))\n",
    "\n",
    "# Use Spark to read in the Ecommerce Customers csv file. You can infer csv schemas. \n",
    "data = spark.read.csv(\"global-hunger-index.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the schema of the DataFrame. Get a view of the datasource structure\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 03-DP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the first 10 instances of the datasource\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a breakdown on info contained in dataframe\n",
    "data.toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-DT\n",
    "Data Transform - Process data source to produce Mean values for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dRemove unused columns. Not nessary but keeps data clean.\n",
    "data = data.drop('Code')\n",
    "data = data.drop('411773-annotations')\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Mean GHI for each year.\n",
    "df_raw = data.groupBy(\"Year\").mean(\"Global Hunger Index (2021)\")\n",
    "df_raw = df_raw.withColumnRenamed(\"avg(Global Hunger Index (2021))\", \"MeanGHIraw\")\n",
    "df_raw.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up MeanGHI and prep data for SQL\n",
    "df_raw.summary().show()\n",
    "df_raw.createOrReplaceTempView(\"df_Raw_Table\")\n",
    "df = spark.sql(\"select Year, round(MeanGHIraw, 4) as MeanGHI from df_Raw_Table\")\n",
    "df\n",
    "df.createOrReplaceTempView(\"df_Table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-DMM\n",
    "Data Transform - Process data source to produce Mean values for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - Actual MeanGHI\n",
    "## Plot Initial MeanGHI data\n",
    "df1=spark.sql(\"Select * from df_Table order by Year\")\n",
    "df1.show()\n",
    "pdf1=df1.toPandas()\n",
    "pdf1.plot(kind='line', x='Year',y='MeanGHI', linestyle=\"solid\", \n",
    "          marker=\"o\", color=\"blue\", title=\"Actual MeanGHI\", xlabel='Year', ylabel='MeanGHI')\n",
    "actual = pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 1. UN - Original GHI prediction Values only\n",
    "## Plot Initial MeanGHI data minus the last reading after COVID\n",
    "df1b=spark.sql(\"Select * from df_Table order by Year limit 3\")\n",
    "#df1b.show()\n",
    "pdf1=df1b.toPandas()\n",
    "\n",
    "X = np.array(df1b.select(\"Year\").collect())\n",
    "Y = np.array(df1b.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg1 = LinearRegression().fit(X, Y)\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 1. Original GHI prediction - Outputs')\n",
    "print(f'R2 score: {reg1.score(X, Y)}')\n",
    "print(f'Coefficients: {reg1.coef_}')\n",
    "print(f'Intercept: {reg1.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2000], [2006], [2012], [2021] ]\n",
    "future = reg1.predict(np.array(predict_years))\n",
    "\n",
    "#future[1] = future[0] \n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_2nd=new_row.select(\"MeanGHI\")\n",
    "plt_2nd = plt_2nd.toPandas().unstack()\n",
    "\n",
    "#new_data = np.column_stack((predict_years, future))\n",
    "#new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "#plt_2nd=new_row.select(\"MeanGHI\")\n",
    "#plt_2nd = future\n",
    "#.toPandas().unstack()\n",
    "\n",
    "plt_1st = pdf1['MeanGHI']\n",
    "plt_1st[3] = 0\n",
    "plt_2nd = plt_2nd['MeanGHI']\n",
    "plt_2nd[0] = 0\n",
    "plt_2nd[1] = 0\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "#print(\"plt_2nd\")\n",
    "#print(plt_2nd)\n",
    "\n",
    "df5 = pd.DataFrame({'Current': plt_1st.values,\n",
    "                    'Future': plt_2nd.values},\n",
    "                    index=[ 2000, 2006, 2012, 2021 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"1. UN - Original GHI prediction Values only\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')\n",
    "origProj_plt_1st = plt_1st\n",
    "origProj_plt_2nd = plt_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 2. UN - Actual v Planned Original GHI Values only (Figure 9)\n",
    "## Plot Initial MeanGHI data minus the last reading after COVID\n",
    "df1b=spark.sql(\"Select * from df_Table order by Year limit 3\")\n",
    "#df1b.show()\n",
    "pdf1=df1b.toPandas()\n",
    "\n",
    "X = np.array(df1b.select(\"Year\").collect())\n",
    "Y = np.array(df1b.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg2 = LinearRegression().fit(X, Y)\n",
    "#reg.score(X, Y)\n",
    "#reg.coef_\n",
    "#reg.intercept_\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 2. GHI Original Tracked & Variation Point - Outputs')\n",
    "print(f'R2 score: {reg2.score(X, Y)}')\n",
    "print(f'Coefficients: {reg2.coef_}')\n",
    "print(f'Intercept: {reg2.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2000], [2006], [2012], [2021], [2027], [2033], [2039] ]\n",
    "future = reg2.predict(np.array(predict_years))\n",
    "\n",
    "#future[1] = future[0] \n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_2nd=new_row.select(\"MeanGHI\")\n",
    "plt_2nd = plt_2nd.toPandas().unstack()\n",
    "\n",
    "#new_data = np.column_stack((predict_years, future))\n",
    "#new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "#plt_2nd=new_row.select(\"MeanGHI\")\n",
    "#plt_2nd = future\n",
    "#.toPandas().unstack()\n",
    "\n",
    "plt_1st = pdf1['MeanGHI']\n",
    "plt_1st[3] = 0\n",
    "plt_2nd = plt_2nd['MeanGHI']\n",
    "plt_2nd[0] = 0\n",
    "plt_2nd[1] = 0\n",
    "actual_data = actual['MeanGHI']\n",
    "#  Init lower part of dataframe first\n",
    "x = 8\n",
    "while x<11:\n",
    "    #print(\"Init: %s\" % (x))\n",
    "    actual_data.loc[x]=0\n",
    "    x += 1\n",
    "\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "#print(\"plt_2nd\")\n",
    "#print(plt_2nd)\n",
    "#print(\"Actual_data\")\n",
    "#print(actual_data)\n",
    "\n",
    "df5 = pd.DataFrame({'Original': plt_2nd.values,\n",
    "                    'Actual': actual_data.values},\n",
    "                    index=[ 2000, 2006, 2012, 2021, 2027, 2033, 2039 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"2. UN - GHI Original Tracked & Variation Point\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')\n",
    "origProj_plt_1st = plt_1st\n",
    "origProj_plt_2nd = plt_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 3. UN - Actual v Planned Trend line GHI Prediction (Figure ?)\n",
    "## Plot Initial MeanGHI data minus the last reading after COVID\n",
    "df1b=spark.sql(\"Select * from df_Table order by Year limit 4\")\n",
    "#df1b.show()\n",
    "pdf1=df1b.toPandas()\n",
    "\n",
    "X = np.array(df1b.select(\"Year\").collect())\n",
    "Y = np.array(df1b.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg3 = LinearRegression().fit(X, Y)\n",
    "#reg.score(X, Y)\n",
    "#reg.coef_\n",
    "#reg.intercept_\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 3. GHI Actual/Original vs Original Prediction - Outputs')\n",
    "print(f'R2 score: {reg3.score(X, Y)}')\n",
    "print(f'Coefficients: {reg3.coef_}')\n",
    "print(f'Intercept: {reg3.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2000], [2006], [2012], [2021] ]\n",
    "future = reg3.predict(np.array(predict_years))\n",
    "\n",
    "#future[1] = future[0] \n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_2nd=new_row.select(\"MeanGHI\")\n",
    "plt_2nd = plt_2nd.toPandas().unstack()\n",
    "\n",
    "#new_data = np.column_stack((predict_years, future))\n",
    "#new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "#plt_2nd=new_row.select(\"MeanGHI\")\n",
    "#plt_2nd = future\n",
    "#.toPandas().unstack()\n",
    "\n",
    "plt_1st = pdf1['MeanGHI']\n",
    "#plt_1st[3] = 0\n",
    "plt_2nd = plt_2nd['MeanGHI']\n",
    "#plt_2nd[0] = 0\n",
    "#plt_2nd[1] = 0\n",
    "actual_data = actual['MeanGHI']\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "#print(\"plt_2nd\")\n",
    "#print(plt_2nd)\n",
    "#print(\"Actual\")\n",
    "#print(actual)\n",
    "\n",
    "df5 = pd.DataFrame({'Original': plt_2nd.values,\n",
    "                    'Actual': actual_data.values},\n",
    "                    index=[ 2000, 2006, 2012, 2021 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"3. UN - GHI Actual/Original vs Original Prediction\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')\n",
    "origProj_plt_1st = plt_1st\n",
    "origProj_plt_2nd = plt_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 4. UN - Actual v Planned Trend line GHI Prediction (Figure ?)\n",
    "## Plot Initial MeanGHI data minus the last reading after COVID\n",
    "df1b=spark.sql(\"Select * from df_Table order by Year limit 4\")\n",
    "#df1b.show()\n",
    "pdf1=df1b.toPandas()\n",
    "\n",
    "X = np.array(df1b.select(\"Year\").collect())\n",
    "Y = np.array(df1b.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg4 = LinearRegression().fit(X, Y)\n",
    "#reg.score(X, Y)\n",
    "#reg.coef_\n",
    "#reg.intercept_\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 4. Actual v New Prediction - Outputs')\n",
    "print(f'R2 score: {reg4.score(X, Y)}')\n",
    "print(f'Coefficients: {reg4.coef_}')\n",
    "print(f'Intercept: {reg4.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2000], [2006], [2012], [2021], [2027], [2033], [2039], [2043], [2049], [2055], [2061] ]\n",
    "future = reg4.predict(np.array(predict_years))\n",
    "\n",
    "#future[1] = future[0] \n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_2nd=new_row.select(\"MeanGHI\")\n",
    "plt_2nd = plt_2nd.toPandas().unstack()\n",
    "\n",
    "#new_data = np.column_stack((predict_years, future))\n",
    "#new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "#plt_2nd=new_row.select(\"MeanGHI\")\n",
    "#plt_2nd = future\n",
    "#.toPandas().unstack()\n",
    "\n",
    "plt_1st = pdf1['MeanGHI']\n",
    "#  Init lower part of dataframe first\n",
    "x = 7\n",
    "while x<11:\n",
    "    #print(\"Init: %s\" % (x))\n",
    "    plt_1st.loc[x]=0\n",
    "    x += 1\n",
    "\n",
    "#plt_1st[3] = 0\n",
    "plt_2nd = plt_2nd['MeanGHI']\n",
    "#plt_2nd[0] = 0\n",
    "#plt_2nd[1] = 0\n",
    "actual_data = actual['MeanGHI']\n",
    "x = 4\n",
    "while x<11:\n",
    "    #print(\"Init: %s\" % (x))\n",
    "    actual_data.loc[x]=0\n",
    "    x += 1\n",
    "\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "#print(\"plt_2nd\")\n",
    "#print(plt_2nd)\n",
    "#print(\"Actual\")\n",
    "#print(actual)\n",
    "\n",
    "df5 = pd.DataFrame({'New Predict': plt_2nd.values,\n",
    "                    'Actual': actual_data.values},\n",
    "                    index=[ 2000, 2006, 2012, 2021, 2027, 2033, 2039, 2043, 2049, 2055, 2061 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"4. UN - Actual v New Prediction\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')\n",
    "#origProj_plt_1st = plt_1st\n",
    "#origProj_plt_2nd = plt_2nd\n",
    "origFullProj_plt_2nd = plt_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 5. Current Future prediction\n",
    "## Plot Initial MeanGHI data including the reading after COVID projecting out to zero\n",
    "\n",
    "df2 = spark.sql(\"Select Year, MeanGHI from df_Table order by Year limit 4\")\n",
    "\n",
    "X = np.array(df2.select(\"Year\").collect())\n",
    "Y = np.array(df2.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg5 = LinearRegression().fit(X, Y)\n",
    "#reg.score(X, Y)\n",
    "#reg.coef_\n",
    "#reg.intercept_\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 5. Current Future prediction - Outputs')\n",
    "print(f'R2 score: {reg5.score(X, Y)}')\n",
    "print(f'Coefficients: {reg5.coef_}')\n",
    "print(f'Intercept: {reg5.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2027], [2033], [2039], [2043], [2049], [2055], [2061] ]\n",
    "future = reg5.predict(np.array(predict_years))\n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "plotYears = X\n",
    "plotMeanGHI = Y\n",
    "#print(\"xxxx\")\n",
    "#print(plotYears)\n",
    "#print(plotMeanGHI)\n",
    "#print(\"xxxx\")\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "plt_future = df2\n",
    "plt_1st=plt_future.select(\"MeanGHI\").toPandas().unstack()\n",
    "\n",
    "x = 4\n",
    "while x<11:\n",
    "    plt_1st.loc['MeanGHI', x]=0\n",
    "    x += 1\n",
    "\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_2nd=new_row.select(\"MeanGHI\")\n",
    "plt_2nd = plt_2nd.toPandas().unstack()\n",
    "\n",
    "#  Init lower part of dataframe first\n",
    "x = 7\n",
    "while x<11:\n",
    "    #print(\"Init: %s\" % (x))\n",
    "    plt_2nd.loc['MeanGHI', x]=0\n",
    "    x += 1\n",
    "\n",
    "# Rearrange dataframe\n",
    "x = 10\n",
    "while x>-1:\n",
    "    #print(\"Rearrange: %s\" % (x))\n",
    "    if x<4:\n",
    "        plt_2nd.loc['MeanGHI',x]=0\n",
    "    else:\n",
    "        plt_2nd.loc['MeanGHI',x]=plt_2nd.loc['MeanGHI',(x-4)]\n",
    "        #print(\"Value: %s\" % (plt_2nd.loc['MeanGHI',(x-4)]))\n",
    "    x -= 1\n",
    "\n",
    "# Cross over point\n",
    "plt_1st.loc['MeanGHI',4]=plt_2nd.loc['MeanGHI',4]\n",
    "\n",
    "plt_future = plt_future.union(new_row)\n",
    "\n",
    "#print(\"....\")\n",
    "#new_row.printSchema()\n",
    "#new_row.show(truncate=False)\n",
    "#plt_future.printSchema()\n",
    "#plt_future.show(truncate=False)\n",
    "#print(\"....\")\n",
    "\n",
    "## Plot Initial MeanGHI data\n",
    "#plt_future.show()\n",
    "plt_df2=plt_future.toPandas()\n",
    "\n",
    "#  Convert to series\n",
    "plt_1st = plt_1st['MeanGHI']\n",
    "plt_2nd = plt_2nd['MeanGHI']\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "#print(\"plt_2nd\")\n",
    "#print(plt_2nd)\n",
    "\n",
    "df5 = pd.DataFrame({'Actual': plt_1st.values,\n",
    "                    'Future': plt_2nd.values},\n",
    "                    index=[ 2000, 2006, 2012, 2021, 2027, 2033, 2039, 2043, 2049, 2055, 2061 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"5. Current Actual/Predicted Timeline\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')\n",
    "curpredict_1st = plt_1st\n",
    "curpredict_2nd = plt_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Graphs - 6. Original/Actual/NewPredict\n",
    "# Example graph\n",
    "\n",
    "df2 = spark.sql(\"Select Year, MeanGHI from df_Table order by Year limit 3\")\n",
    "\n",
    "X = np.array(df2.select(\"Year\").collect())\n",
    "Y = np.array(df2.select(\"MeanGHI\").collect())\n",
    "\n",
    "reg6 = LinearRegression().fit(X, Y)\n",
    "#reg.score(X, Y)\n",
    "#reg.coef_\n",
    "#reg.intercept_\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 6. Original/Actual/NewPredict - Outputs')\n",
    "print(f'R2 score: {reg6.score(X, Y)}')\n",
    "print(f'Coefficients: {reg6.coef_}')\n",
    "print(f'Intercept: {reg6.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "# Kept adding a year on and rerunning until the value reached/past Zero.\n",
    "predict_years = [ [2012], [2021], [2027], [2033], [2039], [2043], [2049], [2055], [2061] ]\n",
    "future = reg6.predict(np.array(predict_years))\n",
    "#print(\"Future predictions are %s\" % (future))\n",
    "\n",
    "plotYears = X\n",
    "plotMeanGHI = Y\n",
    "#print(\"xxxx\")\n",
    "#print(plotYears)\n",
    "##print(plotMeanGHI)\n",
    "##print(\"xxxx\")\n",
    "\n",
    "columns = [\"Year\", \"MeanGHI\"]\n",
    "#plt_future = future\n",
    "#plt_1st=plt_future.select(\"MeanGHI\").toPandas().unstack()\n",
    "\n",
    "#x = 4\n",
    "#while x<11:\n",
    "#    plt_1st.loc['MeanGHI', x]=0\n",
    "#    x += 1\n",
    "\n",
    "new_data = np.column_stack((predict_years, future))\n",
    "new_row = spark.createDataFrame(new_data.tolist(), schema=columns)\n",
    "plt_1st=new_row.select(\"MeanGHI\")\n",
    "plt_1st = plt_1st.toPandas().unstack()\n",
    "\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "\n",
    "##  Init lower part of dataframe first\n",
    "x = 7\n",
    "while x<11:\n",
    "    #print(\"Init: %s\" % (x))\n",
    "    plt_1st.loc['MeanGHI', x]=0\n",
    "    x += 1\n",
    "\n",
    "\n",
    "## Rearrange dataframe\n",
    "x = 10\n",
    "while x>-1:\n",
    "    #print(\"Rearrange: %s\" % (x))\n",
    "    if x<2:\n",
    "        plt_1st.loc['MeanGHI',x]=0\n",
    "    else:\n",
    "        if plt_1st.loc['MeanGHI',(x-2)]>0:\n",
    "            plt_1st.loc['MeanGHI',x]=plt_1st.loc['MeanGHI',(x-2)]\n",
    "        else:\n",
    "            plt_1st.loc['MeanGHI',x]=0\n",
    "        #print(\"Value: %s\" % (plt_2nd.loc['MeanGHI',(x-4)]))\n",
    "    x -= 1\n",
    "\n",
    "## Cross over point\n",
    "#plt_1st.loc['MeanGHI',4]=plt_2nd.loc['MeanGHI',4]\n",
    "\n",
    "#plt_future = plt_future.union(new_row)\n",
    "\n",
    "##print(\"....\")\n",
    "##new_row.printSchema()\n",
    "##new_row.show(truncate=False)\n",
    "##plt_future.printSchema()\n",
    "##plt_future.show(truncate=False)\n",
    "##print(\"....\")\n",
    "\n",
    "## Plot Initial MeanGHI data\n",
    "##plt_future.show()\n",
    "#plt_df2=plt_future.toPandas()\n",
    "\n",
    "##  Convert to series\n",
    "#plt_1st = plt_1st['MeanGHI']\n",
    "#plt_2nd = plt_2nd['MeanGHI']\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "##print(\"plt_2nd\")\n",
    "##print(plt_2nd)\n",
    "#print(\"curpredict_1st\")\n",
    "#print(curpredict_1st)\n",
    "#print(\"curpredict_2nd\")\n",
    "#print(curpredict_2nd)\n",
    "#print(\"plt_1st\")\n",
    "#print(plt_1st)\n",
    "\n",
    "\n",
    "df5 = pd.DataFrame({'Actual':   curpredict_1st.values,\n",
    "                    'Future':   curpredict_2nd.values,\n",
    "                    #'Original': origpredict_2nd.values},\n",
    "                    'Original': plt_1st.values},                   \n",
    "                    index=[ 2000, 2006, 2012, 2021, 2027, 2033, 2039, 2043, 2049, 2055, 2061 ])\n",
    "\n",
    "\n",
    "df5 = df5.replace(0, None)\n",
    "\n",
    "print(df5)\n",
    "\n",
    "df5.plot(kind='line', title=\"6. Original/Actual/NewPrediction Timelines\", linestyle=\"solid\", marker=\"o\", xlabel='Year', ylabel='MeanGHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------------------')\n",
    "print('Model Run - 1. Original GHI prediction - Outputs')\n",
    "print(f'R2 score: {reg1.score(X, Y)}')\n",
    "print(f'Coefficients: {reg1.coef_}')\n",
    "print(f'Intercept: {reg1.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 2. GHI Original Tracked & Variation Point - Outputs')\n",
    "print(f'R2 score: {reg2.score(X, Y)}')\n",
    "print(f'Coefficients: {reg2.coef_}')\n",
    "print(f'Intercept: {reg2.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 3. GHI Actual/Original vs Original Prediction - Outputs')\n",
    "print(f'R2 score: {reg3.score(X, Y)}')\n",
    "print(f'Coefficients: {reg3.coef_}')\n",
    "print(f'Intercept: {reg3.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 4. Actual v New Prediction - Outputs')\n",
    "print(f'R2 score: {reg4.score(X, Y)}')\n",
    "print(f'Coefficients: {reg4.coef_}')\n",
    "print(f'Intercept: {reg4.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 5. Current Future prediction - Outputs')\n",
    "print(f'R2 score: {reg5.score(X, Y)}')\n",
    "print(f'Coefficients: {reg5.coef_}')\n",
    "print(f'Intercept: {reg5.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print('------------------------------------------------')\n",
    "print('Model Run - 6. Original/Actual/NewPredict - Outputs')\n",
    "print(f'R2 score: {reg6.score(X, Y)}')\n",
    "print(f'Coefficients: {reg6.coef_}')\n",
    "print(f'Intercept: {reg6.intercept_}')\n",
    "print('------------------------------------------------')\n",
    "print(\"Run Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
